# Kolosal Agent System - Example Configuration
# This file demonstrates how to use environment variables and relative paths
# for a portable, secure configuration setup.

server:
  port: ${KOLOSAL_PORT:-8081}
  host: ${KOLOSAL_HOST:-127.0.0.1}
  idle_timeout: 300
  allow_public_access: false
  allow_internet_access: false

logging:
  level: ${KOLOSAL_LOG_LEVEL:-INFO}
  file: ${KOLOSAL_LOG_FILE:-}  # Empty means log to console
  access_log: false
  quiet_mode: false
  show_request_details: true

auth:
  enabled: ${KOLOSAL_AUTH_ENABLED:-false}
  require_api_key: ${KOLOSAL_REQUIRE_API_KEY:-false}
  api_key_header: X-API-Key
  api_keys:
    # Add API keys via environment variables in production
    # Example: Set KOLOSAL_API_KEY_1, KOLOSAL_API_KEY_2, etc.
    - ${KOLOSAL_API_KEY:-}
  rate_limit:
    enabled: true
    max_requests: ${KOLOSAL_RATE_LIMIT_REQUESTS:-100}
    window_size: ${KOLOSAL_RATE_LIMIT_WINDOW:-60}
  cors:
    enabled: true
    allow_credentials: false
    max_age: 86400
    allowed_origins:
      - ${KOLOSAL_CORS_ORIGIN_1:-}
    allowed_methods:
      - GET
      - POST
      - PUT
      - DELETE
      - OPTIONS
      - HEAD
      - PATCH
    allowed_headers:
      - Content-Type
      - Authorization
      - X-Requested-With
      - Accept
      - Origin

search:
  enabled: ${KOLOSAL_SEARCH_ENABLED:-true}
  searxng_url: ${KOLOSAL_SEARXNG_URL:-https://searx.stream/}
  timeout: ${KOLOSAL_SEARCH_TIMEOUT:-30}
  max_results: ${KOLOSAL_SEARCH_MAX_RESULTS:-20}
  default_engine: ${KOLOSAL_SEARCH_ENGINE:-}
  api_key: ${KOLOSAL_SEARCH_API_KEY:-}
  enable_safe_search: true
  default_format: json
  default_language: ${KOLOSAL_SEARCH_LANGUAGE:-en}
  default_category: general

database:
  vector_database: ${KOLOSAL_VECTOR_DB:-qdrant}
  retrieval_embedding_model: ${KOLOSAL_RETRIEVAL_MODEL:-all-MiniLM-L6-v2-bf16-q4_k}
  
  qdrant:
    enabled: ${KOLOSAL_QDRANT_ENABLED:-true}
    host: ${KOLOSAL_QDRANT_HOST:-localhost}
    port: ${KOLOSAL_QDRANT_PORT:-6333}
    collection_name: ${KOLOSAL_QDRANT_COLLECTION:-documents}
    default_embedding_model: ${KOLOSAL_QDRANT_EMBEDDING_MODEL:-all-MiniLM-L6-v2-bf16-q4_k}
    timeout: ${KOLOSAL_QDRANT_TIMEOUT:-30}
    api_key: ${KOLOSAL_QDRANT_API_KEY:-}
    max_connections: ${KOLOSAL_QDRANT_MAX_CONN:-10}
    connection_timeout: ${KOLOSAL_QDRANT_CONN_TIMEOUT:-5}
    embedding_batch_size: ${KOLOSAL_QDRANT_BATCH_SIZE:-5}
    
  faiss:
    index_type: ${KOLOSAL_FAISS_INDEX_TYPE:-Flat}
    index_path: ${KOLOSAL_FAISS_INDEX_PATH:-./data/faiss_index}
    dimensions: ${KOLOSAL_FAISS_DIMENSIONS:-1536}
    normalize_vectors: ${KOLOSAL_FAISS_NORMALIZE:-true}
    nlist: ${KOLOSAL_FAISS_NLIST:-100}
    nprobe: ${KOLOSAL_FAISS_NPROBE:-10}
    use_gpu: ${KOLOSAL_FAISS_GPU:-false}
    gpu_device: ${KOLOSAL_FAISS_GPU_DEVICE:-0}
    metric_type: ${KOLOSAL_FAISS_METRIC:-IP}

# Model configuration with environment variable paths
models:
  # LLM Model
  - id: ${KOLOSAL_LLM_MODEL_ID:-qwen2.5-0.5b}
    path: ${KOLOSAL_MODEL_PATH:-./models}/${KOLOSAL_LLM_MODEL_FILE:-qwen2.5-0.5b-instruct-q4_k_m.gguf}
    type: llm
    load_immediately: ${KOLOSAL_LLM_PRELOAD:-true}
    main_gpu_id: ${KOLOSAL_LLM_GPU_ID:-0}
    inference_engine: ${KOLOSAL_LLM_ENGINE:-llama-cpu}
    load_params:
      n_ctx: ${KOLOSAL_LLM_CONTEXT_SIZE:-2048}
      n_keep: ${KOLOSAL_LLM_KEEP_SIZE:-1024}
      use_mmap: ${KOLOSAL_LLM_USE_MMAP:-true}
      use_mlock: ${KOLOSAL_LLM_USE_MLOCK:-false}
      n_parallel: ${KOLOSAL_LLM_PARALLEL:-1}
      cont_batching: ${KOLOSAL_LLM_BATCHING:-true}
      warmup: ${KOLOSAL_LLM_WARMUP:-false}
      n_gpu_layers: ${KOLOSAL_LLM_GPU_LAYERS:-0}
      n_batch: ${KOLOSAL_LLM_BATCH_SIZE:-2048}
      n_ubatch: ${KOLOSAL_LLM_UBATCH_SIZE:-512}
      
  # Embedding Model
  - id: ${KOLOSAL_EMBEDDING_MODEL_ID:-all-MiniLM-L6-v2-bf16-q4_k}
    path: ${KOLOSAL_MODEL_PATH:-./models}/${KOLOSAL_EMBEDDING_MODEL_FILE:-all-MiniLM-L6-v2-bf16-q4_k.gguf}
    type: embedding
    load_immediately: ${KOLOSAL_EMBEDDING_PRELOAD:-true}
    main_gpu_id: ${KOLOSAL_EMBEDDING_GPU_ID:-0}
    inference_engine: ${KOLOSAL_EMBEDDING_ENGINE:-llama-cpu}
    load_params:
      n_ctx: ${KOLOSAL_EMBEDDING_CONTEXT_SIZE:-512}
      use_mmap: ${KOLOSAL_EMBEDDING_USE_MMAP:-true}
      use_mlock: ${KOLOSAL_EMBEDDING_USE_MLOCK:-false}
      embedding_only: true

# Inference engines with platform-aware paths
inference_engines:
  - name: ${KOLOSAL_ENGINE_NAME:-llama-cpu}
    library_path: ${KOLOSAL_ENGINE_PATH:-./build/Debug}/${KOLOSAL_ENGINE_LIBRARY:-llama-cpu.dll}
    version: ${KOLOSAL_ENGINE_VERSION:-1.0.0}
    description: ${KOLOSAL_ENGINE_DESC:-CPU-based inference engine for LLaMA models}
    load_on_startup: ${KOLOSAL_ENGINE_AUTOLOAD:-true}

default_inference_engine: ${KOLOSAL_DEFAULT_ENGINE:-llama-cpu}

features:
  health_check: ${KOLOSAL_HEALTH_CHECK:-true}
  metrics: ${KOLOSAL_METRICS_ENABLED:-true}

# Performance tuning
performance:
  max_memory_usage: ${KOLOSAL_MAX_MEMORY:-auto}
  cache_size: ${KOLOSAL_CACHE_SIZE:-auto}
  worker_threads: ${KOLOSAL_WORKER_THREADS:-auto}
  request_timeout: ${KOLOSAL_REQUEST_TIMEOUT:-30000}

# Data directories (all relative to working directory by default)
data_paths:
  models: ${KOLOSAL_MODEL_PATH:-./models}
  data: ${KOLOSAL_DATA_PATH:-./data}
  logs: ${KOLOSAL_LOG_PATH:-./logs}
  cache: ${KOLOSAL_CACHE_PATH:-./cache}
  temp: ${KOLOSAL_TEMP_PATH:-./tmp}
